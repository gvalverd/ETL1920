# -*- coding: utf-8 -*-
"""NBA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15XHJWOcoScSB7wFS0CqyzK-FtspphQCj
"""



!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
!tar xf spark-2.4.7-bin-hadoop2.7.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.7-bin-hadoop2.7"

import findspark
findspark.init()
from pyspark import SparkContext
sc = SparkContext.getOrCreate()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

import seaborn as sns
import pandas as pd

"""CREATION RDD FROM A FILE


"""

raw_data = "./partidosNBA.csv"
rdd = sc.textFile(raw_data)

first_row = raw_data.take(1)[0]
first_row



rdd = rdd.filter(lambda x: first_row not in x)

rdd = rdd.filter(lambda x: "Playoffs" not in x)

rdd.take(5)



def intervalo(x):
  x = int(x)
  if x < 70:
    return "intervalo1"
  elif x < 90:
    return "intervalo2"
  elif x < 100:
    return "intervalo3"
  elif x < 120:
    return "intervalo4"
  elif x < 140:
    return "intervalo5"
  else:
    return "intervalo6"

def clave_valor(line):
  linea = line.split(":")
  bin = intervalo(linea[4])
  valor = int(linea[4])
  return (bin, valor)

parseado = rdd.map(clave_valor)

parseado.reduceByKey(lambda a, b: a + b).collect()

histograma = parseado.reduceByKey(lambda a, b: a + b).collect()



df = pd.DataFrame(histograma)

df = df.sort_values(by=0)

"""PLOT"""

sns.barplot(x=0, y=1, data=df)

