# -*- coding: utf-8 -*-
"""examen1920v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SZMF7pjMKpayzX3IgK2joxMQD5D906K7

# BEATRIZ CÁRDABA RICO
## 1. The World Bank's international debt data
<p>No es que los humanos solo tengamos deudas para administrar nuestras necesidades. Un país también puede endeudarse para administrar su economía. Por ejemplo, el gasto en infraestructura es un ingrediente costoso requerido para que los ciudadanos de un país lleven una vida cómoda. El Banco Mundial es la organización que proporciona deuda a los países.</p>

<!-- <p>En este notebook, vamos a analizar los datos de la deuda internacional recopilados por el Banco Mundial. El conjunto de datos contiene información sobre el monto de la deuda (en USD) que deben los países en desarrollo en varias categorías.</p>  -->

"Disbursements on external debt, long-term (DIS, current US$)",DT.DIS.DLXF.CD
"Interest payments on external debt, long-term (INT, current US$)",DT.INT.DLXF.CD
"PPG, bilateral (AMT, current US$)",DT.AMT.BLAT.CD
"PPG, bilateral (DIS, current US$)",DT.DIS.BLAT.CD
"PPG, bilateral (INT, current US$)",DT.INT.BLAT.CD
"PPG, multilateral (AMT, current US$)",DT.AMT.MLAT.CD
"PPG, multilateral (DIS, current US$)",DT.DIS.MLAT.CD
"PPG, multilateral (INT, current US$)",DT.INT.MLAT.CD
"PPG, official creditors (AMT, current US$)",DT.AMT.OFFT.CD
"PPG, official creditors (DIS, current US$)",DT.DIS.OFFT.CD
"PPG, official creditors (INT, current US$)",DT.INT.OFFT.CD
"Principal repayments on external debt, long-term (AMT, current US$)",DT.AMT.DLXF.CD
"Interest payments on external debt, private nonguaranteed (PNG) (INT, current US$)",DT.INT.DPNG.CD
"PPG, bonds (AMT, current US$)",DT.AMT.PBND.CD
"PPG, bonds (INT, current US$)",DT.INT.PBND.CD
"PPG, commercial banks (AMT, current US$)",DT.AMT.PCBK.CD
"PPG, commercial banks (DIS, current US$)",DT.DIS.PCBK.CD
"PPG, commercial banks (INT, current US$)",DT.INT.PCBK.CD
"PPG, other private creditors (AMT, current US$)",DT.AMT.PROP.CD
"PPG, other private creditors (DIS, current US$)",DT.DIS.PROP.CD
"PPG, other private creditors (INT, current US$)",DT.INT.PROP.CD
"PPG, private creditors (AMT, current US$)",DT.AMT.PRVT.CD
"PPG, private creditors (DIS, current US$)",DT.DIS.PRVT.CD
"PPG, private creditors (INT, current US$)",DT.INT.PRVT.CD
"Principal repayments on external debt, private nonguaranteed (PNG) (AMT, current US$)",DT.AMT.DPNG.CD

<p>Vamos a encontrar las respuestas a preguntas como:

<p>¿Cuál es el monto total de la deuda que deben los países enumerados en el conjunto de datos?
<p>¿Qué país posee la cantidad máxima de deuda y cómo se ve esa cantidad?
<p>¿Cuál es el monto promedio de la deuda de los países a través de diferentes indicadores de deuda?
    
Además tenemos otro dataset en el que encontramos información histórica de algunos índices de desarrollo, entre los que se encuentran algunos de deuda como son:

Series Name,Series Code
"Birth rate, crude (per 1,000 people)",SP.DYN.CBRT.IN

"Central government debt, total (current LCU)",GC.DOD.TOTL.CN

"Central government debt, total (% of GDP)",GC.DOD.TOTL.GD.ZS

#### 1. Inicializar y cargar el contexto spark
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
!tar xf spark-2.4.7-bin-hadoop2.7.tgz
!pip install -q findspark


import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.7-bin-hadoop2.7"

import findspark
findspark.init()
from pyspark import SparkContext

from pyspark import SparkContext
from pyspark.sql import *
from pyspark.sql import SQLContext, functions as F, Row
from pyspark.sql.types import *
from pyspark.sql.types import StringType, IntegerType

# Librería para dar formato a las salidas obtenidas
import pandas as pd
# Librería para aplicar expresiones regulares en el parseado
import re
# librería para parsear las fechas con formato date
from datetime import datetime
# Librería que permite descargar información de una url desde python
import urllib
from urllib.request import urlretrieve
# Librería para llamar a funciones relacionadas con el sistema operativo
import os

sc = SparkContext.getOrCreate()

sqlContext = SQLContext(sc)

"""Importamos los datos desde CSV textfil de spark:

"""

indicadores_desarrollo = "indicadores_desarrollo.csv"
raw_desarrollo = sc.textFile(indicadores_desarrollo)

indicadores_deuda = "indicadores_deuda.csv"
raw_deuda = sc.textFile(indicadores_deuda)

"""# PARSEO
 -  DATOS DE DESARROLLO
"""

raw_desarrollo.take(5) # visualizamos las 5 primeras filas

"""Comprobamos que las columnas están separadas por comas, parseamos los datos de desarrollo:"""

dt_desarrollo = raw_desarrollo.map(lambda x: x.split(",")) # para separar los diferentes campos

"""Visualizamos que ahora las columnas se diferencian correctamente:



"""

dt_desarrollo.take(2) # visualizamos las dos primeras filas y comprobamos que se diferencian las columnas correctamente

"""- DATOS DEUDA"""

raw_deuda.take(5)  # visualizamos las 5 primeras filas

"""Comprobamos que las columnas están separadas por comas, parseamos los datos de deuda:"""

dt_deuda = raw_deuda.map(lambda x: x.split(",")) # para separar los diferentes campos

dt_deuda.take(2) # visualizamos las dos primeras filas y comprobamos que se diferencian las columnas correctamente

"""##### 2. Número de países distintos en cada dataset. Coinciden?

 - Desarrollo:

En primer lugar vamos a comprobar los datos diferentes para la columna de country_name en los datos de desarrollo. Lo realizamos mediante un distict count. NO se ha eliminado la fila de la cabecera por lo que al resultado habrá que restarle 1
"""

(dt_desarrollo.map(lambda line: line[0]).distinct().count())-1 # realizamos un distict count de los paises y eliminamos el valor de la cabecera pra que no lo cuente

countries_desarrollo = dt_desarrollo.map(lambda line: line[0]).\
                                     filter(lambda line: line[0] != 'country_name').\
                                     distinct()

countries_desarrollo.take(51)

""" - Deuda:

 En primer lugar vamos a comprobar los datos diferentes para la columna de country_name en los datos de desarrollo. Lo realizamos mediante un distict count. NO se ha eliminado la fila de la cabecera por lo que al resultado habrá que restarle 1
"""

(dt_deuda.map(lambda line: line[0]).distinct().count())-1 # hacemos un count ditict de los paises y restamos 1 que viene de la cabecera

"""Eliminamos la cabecera de la columna country_name:"""

# queremos seleccionaar la columna 0 y de esta quere filtrar y que no aparezca la cabecera
countries_deuda = dt_deuda.map(lambda line: line[0]).\
                           filter(lambda line: line[0] != 'country_name').\
                           distinct()

countries_deuda.take(123) # visualizamos los 123 países de deuda

"""- Solución 2:

En esta pregunat concluimos que el data set desarrollo contine 51 países diferentes y el datset de duda contiene 123 países diferenets

##### 3. Total de deuda contraida por cada pais: total amount of debt (in USD) DT.AMT.MLAT.CD

Lo que vamos a realixar en este ejercicio es un map apara seleccionar las columnas en las que estamos interesados. En primer lugar nos interesa la columna country_name, que ocupa la posición 0 y en segundo lugar nos interesa la columna DT.AMT.MLAT.CD, que ocupa la posición 5. Ambas en el data set de deuda.

En el parseo de datos y comprobando el dataset deuda en el csv, vista excel, se ha visto que se produce un error ya que hay países que en la primera columna "country_name" tienen una coma, por lo que su parseo es erróneo. Comporbamos que países tienen su parseo erróneo visualizzando las tres primeras columnas del data set deuda:
"""

dt_deuda.map(lambda x: (x[0], x[1], x[2])).collect()

"""Los países pobrematicos son aquellos que en su columna [2] tienen el código del país en vez de una cifra. Tras observar que esto no sucede en muchos países vamos a eliminar éstos de la muestra para llegar al objetivo del ejercicio, proporcionar la relación entre cada país y la deuda"""

# seleccionamos las columnas que nos interesn, en este caso la posicion 0 y 1 para identificar al país  y la 5.
# como he comentado anteriormente vamos a eliminar de la miestra los países mal parseados porque sino apareciría como deuda DT.AMT.MLAT.CD otra columna diferente

dt_deuda_3 = dt_deuda.map(lambda x: (x[0], x[1],x[2], x[5])).\
                filter(lambda x: x[1] != '').\
                filter(lambda x: x[1] != ("") ).\
                filter(lambda x: x[2] != ("COD") ).\
                filter(lambda x: x[2] != ("COG") ).\
                filter(lambda x: x[2] != ("EGY") ).\
                filter(lambda x: x[2] != ("MKD") ).\
                filter(lambda x: x[2] != ("VEN") ).\
                filter(lambda x: x[2] != ("YEM") ).\
                filter(lambda x: x[2] != ('IRN') ).\
                filter(lambda x: x[2] != ("GMB") )

dt_deuda_3.map(lambda x: (x[0], x[3])).collect()

"""##### 4. Media de los indicadores de deuda (tabla uno): DT.AMT.BLAT.CD, DT.DIS.BLAT.CD, DT.INT.BLAT.CD.

Para conseguir el resuultado de esta cuestión se va a proceder con diferentes procedimientos:

- Primero vamos a seleccionar las filas de estos indicadorees de deuda, que están en la posición 2,11 y 18.


Como en el ejercicio anterior, como hay países que no se han parseado correctamente los eliminamos de la muestra. Seleccionamos las filas que nos interesan. en este caso si no hubieramos eliminado bien las filas el resultado de la media de DT.AMT.BLAT.CD no se podría realizar porquie habría elementos str
"""

# seleccionamos las columnas que nos intereasn en este caso y eliminamos las filas que han dado error en el parseo

dt_deuda_filter_4 = dt_deuda.map(lambda x: (x[0], x[1], x[2], x[11], x[18])).\
                filter(lambda x: x[1] != '').\
                filter(lambda x: x[1] != ("") ).\
                filter(lambda x: x[2] != ("COD") ).\
                filter(lambda x: x[2] != ("COG") ).\
                filter(lambda x: x[2] != ("EGY") ).\
                filter(lambda x: x[2] != ("MKD") ).\
                filter(lambda x: x[2] != ("VEN") ).\
                filter(lambda x: x[2] != ("YEM") ).\
                filter(lambda x: x[2] != ('IRN') ).\
                filter(lambda x: x[2] != ("GMB") )

dt_deuda_filter_4.take(200) # visualizamos que el filtro es correcto

"""- Para poder calcular la media hay que eliminar las cabeceras de cada columna:"""

header = dt_deuda_filter_4.take(1)[0] # nombramos las cabecera
header # visualizamos que ha seleccionado correctamente la cabecera

# eliminamos del rdd la cabecera pra poder realizar cáculos numericos con las columnas
dt_deuda_filter_4 = dt_deuda_filter_4 \
    .filter(lambda line: line!=header) # selecciona todas las filas menos header

dt_deuda_filter_4.take(1) # comprobamos que la  primera fila no es el header

"""- Tenemos que pasar todas las columnas a tipo float para poder operar con ellas, Para poder hacerlo hay que eliminar aquellas filas que tengan valores nulos:"""

dt_deuda_filter_clean_4 = dt_deuda_filter_4.map(lambda x: (x[0], x[1], x[2], x[3], x[4])).\
                filter(lambda x: x[2] != '').\
                filter(lambda x: x[2] != ("")).\
                filter(lambda x: x[3] != '').\
                filter(lambda x: x[3] != ("")).\
                filter(lambda x: x[4] != '').\
                filter(lambda x: x[4] != ("") )

"""Nos aseguramos que todos los datos sobre los que se van a arealizar los cáculos son numéricos mediante la siguiente función:"""

dt_deuda_filter_clean_4 = dt_deuda_filter_clean_4.map(lambda x: (str(x[0]), str(x[1]), float(x[2]), float(x[3]), float(x[4]) ))

"""- Calculamos las medias de cada columna:

### Solución

- Media: 'DT.AMT.BLAT.CD'
"""

dt_deuda_filter_clean_4.map(lambda x: (x[2])).mean() # DT.AMT.BLAT.CD'

"""   - Media: 'DT.DIS.BLAT.CD'"""

dt_deuda_filter_clean_4.map(lambda x: (x[3])).mean() # 'DT.DIS.BLAT.CD'

"""  - Media: 'DT.INT.BLAT.CD'"""

dt_deuda_filter_clean_4.map(lambda x: (x[4])).mean() # 'DT.INT.BLAT.CD'

"""### 5. Los 20 paises con DT.AMT.DLXF.CD más alto. Columna: DT.AMT.DLXF.CD 


En primer lugar seleccionamos las columnas que vamos a usar y eliminamos las filas que se han parseado mal
"""

dt_deuda_filter_5 = dt_deuda.map(lambda x: (x[0], x[1], x[3])).\
                filter(lambda x: x[1] != '').\
                filter(lambda x: x[1] != ("") ).\
                filter(lambda x: x[1] != ("COD") ).\
                filter(lambda x: x[1] != ("COG") ).\
                filter(lambda x: x[1] != ("EGY") ).\
                filter(lambda x: x[1] != ("MKD") ).\
                filter(lambda x: x[1] != ("VEN") ).\
                filter(lambda x: x[1] != ("YEM") ).\
                filter(lambda x: x[1] != ('IRN') ).\
                filter(lambda x: x[1] != ("GMB") )

dt_deuda_filter_5.take(5) # comprobamos que se carga

"""A continucación:

- Seleccionamos las columnas a estudiar, posicion 0 y 2.
- Eliminamos las filas con valores no infados.
- eliminamos el header (otra manera a la del ejercicio anterior)
"""

dt_deuda_DT_AMT_DLXF_CD = dt_deuda_filter_5.map(lambda x: (x[0], x[2])).filter(lambda x: x[1] != '').filter(lambda x: x[0] != 'country_name')

dt_deuda_DT_AMT_DLXF_CD.take(5) # comporbamos que se ha filtado correctamente

"""Cambiamos el tipo de los datos para que se puedan ordenar:"""

dt_deuda_DT_AMT_DLXF_CD = dt_deuda_DT_AMT_DLXF_CD.\
        map(lambda x: (str(x[0]), float(x[1])))

"""## Solución:

Ordenamos según el valor de la columna 1, DT_AMT_DLXF_CD, de mayor a menor y seleccionamos las 20 primeras
"""

(dt_deuda_DT_AMT_DLXF_CD.sortBy(lambda x: x[1])
    .zipWithIndex()
    .map(lambda x: x[0])
    .sortBy(lambda x: x[1], ascending= False)
).take(20)

"""##### 6. Pais con los datos informados todos los años."""

dt_desarrollo.take(2) # visualizamos los datos desarrollo para ver las variables y el orden que tienen

"""Vemos los diferentes años posibles:"""

years_desarrollo = dt_desarrollo.map(lambda line: line[2]).distinct()
years_desarrollo.take(10)

"""Hay 4 años disponibles. Seleccionaremos estos países agrupando los datos por país y sumamos cuantas veces aparece cada país. Nos interesan los paises que aparezzcan 4 veces"""

dt_desarrollo.map(lambda x: (x[0], x[2]))\
    .groupByKey()\
    .mapValues(lambda vals: len((vals)))\
    .sortByKey()\
    .filter(lambda x: x[1] ==4)\
    .collect()

"""Malawi es el único país que tiene informado los 4 años

##### 7. Media anual de los distintos indicadores de desarrollo

En primer lugar como nos interesa calcular la media de los datos de desarrollo vamos a quitar las cabeceras para poder hjacer los calculos
"""

header = dt_desarrollo.take(1)[0]
header

# Seleccionamos la primera fila como la cabecera 
header = dt_desarrollo.take(1)[0]
    # Eliminamos la cabecera del rdd para poder trabajar con el
dt_desarrollo_nh= dt_desarrollo \
    .filter(lambda line: line!=header)

dt_desarrollo_nh.take(2) # comporbamos que hemos eliminado la cabecera

"""En el ejercicio anterior al visualizar os datos hemos observado que hay tres filas que no se han parseado correctamente y hay que eliminarlas para poder realizar las medias.
Seleccionamos los datos que nos interesan y filtramos:
"""

dt_desarrollo_filter_7 = dt_desarrollo_nh.map(lambda x: (x[0], x[2], x[3], x[4], x[5])).\
                filter(lambda x: x[1] != '').\
                filter(lambda x: x[1] != ("") ).\
                filter(lambda x: x[1] != ("KOR") ).\
                filter(lambda x: x[1] != ("FSM") ).\
                filter(lambda x: x[1] != ("BHS") )

dt_desarrollo_filter_7.take(5) # visualizamos que se han filtardo los datos correctamente

"""Cambiamos el formato de las columnas:

 Indicamos que la columna 1 es un dato  que nos explica el año, y el resto de columnas son de formato int
"""

dt_desarrollo_filter_7.map(lambda l: (year(l[1]),  int(l[2]), int(l[3]), int(l[4]), int(l[5])))

dt_desarrollo_filter_7.take(5)

""" Seleccionamos la primera fila de la que queremos obtener la media:"""

dt_desarrollo_GC_DOD_TOTL_CN = dt_desarrollo_filter_7.map(lambda x: (x[1], x[2])).\
                filter(lambda x: x[1] != '')

"""Definimos una función según lo dado en el notebok Logs NASA Arturo Sanchez. Sin embargo, viendo el resultado me he dado cuenta que lo que hace es un count para cada año y no la media como interesaba en ete caso"""

unique_result = (dt_desarrollo_GC_DOD_TOTL_CN.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(set)
          .map(lambda x: (x[0], len(x[1]))))

length_result = (dt_desarrollo_GC_DOD_TOTL_CN.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(len))

joined = length_result.join(unique_result).map(lambda a: (a[0], (a[1][0])/(a[1][1]))).collect()
day = [x[0] for x in joined]
count = [x[1] for x in joined]
day_count_dct = {'Día':day, 'Media':count}
day_count_df = pd.DataFrame(day_count_dct )

day_count_df

"""Repetimos el procedimiento para el segundo indicador:"""

dt_desarrollo_GC_DOD_TOTL_GD_ZS = dt_desarrollo_filter.map(lambda x: (x[1], x[3])).\
                filter(lambda x: x[1] != '')

unique_result = (dt_desarrollo_GC_DOD_TOTL_GD_ZS.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(set)
          .map(lambda x: (x[0], len(x[1]))))

length_result = (dt_desarrollo_GC_DOD_TOTL_GD_ZS.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(len))

joined = length_result.join(unique_result).map(lambda a: (a[0], (a[1][0])/(a[1][1]))).collect()
day = [x[0] for x in joined]
count = [x[1] for x in joined]
day_count_dct = {'Día':day, 'Media':count}
day_count_df_2 = pd.DataFrame(day_count_dct )

day_count_df_2

"""Repetimos el procedimiento para el tercer indicador:"""

dt_desarrollo_SP_DYN_CBRT_IN = dt_desarrollo_filter.map(lambda x: (x[1], x[4])).\
                filter(lambda x: x[1] != '')

unique_result = (dt_desarrollo_SP_DYN_CBRT_IN.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(set)
          .map(lambda x: (x[0], len(x[1]))))

length_result = (dt_desarrollo_SP_DYN_CBRT_IN.map(lambda line:  ((line[0]),line[0]))
          .groupByKey().mapValues(len))

joined = length_result.join(unique_result).map(lambda a: (a[0], (a[1][0])/(a[1][1]))).collect()
day = [x[0] for x in joined]
count = [x[1] for x in joined]
day_count_dct = {'Día':day, 'Media':count}
day_count_df_3 = pd.DataFrame(day_count_dct )

day_count_df_3

"""Como esta función no ha servido para el resultado que pedía el ejercicio  he decidido parar los datos a formato tabla sql:"""

desarrollo_DF = sqlContext.createDataFrame(dt_desarrollo_filter) # convertimos el rdd en un tabla sql

desarrollo_DF.show(10) # observamos la tabla sql y las nuevas cabeceras:

"""- Correspondecia de las columnas con las cabeceras
 
 _3 = 'GC.DOD.TOTL.CN',

 _4 ='GC.DOD.TOTL.GD.ZS',

 _5 = 'SP.DYN.CBRT.IN'

Se calcula la media de los valores de cada columna agrupando por año:
"""

from pyspark.sql.functions import mean # importamos la fórmula para calcular la media

(desarrollo_DF
    .groupBy(("_2")) # agrupamos por año
    .agg(mean("_3"),mean("_4"),mean("_5")) # hacemos la media de cada columna 
    .show())

"""##### 8. Podrías decirme el total de deuda acumulada DT.AMT.MLAT.CD por los 10 países con un valor en media menor de SP.DYN.CBRT.IN

Para realizar este ejercico aprovechamos los cálculos y transformaciones del ejercico anterior. Ahora creamos una tabla en formto sql que contenga los 10 paises con un valor en media menor en el indicador SP.DYN.CBRT.IN.

Crecamos la tabla que asigne a cada país el valor medio de las observaciones del indicador P.DYN.CBRT.IN:
"""

desarrollo_DF_sol = (desarrollo_DF
    .groupBy(("_1")) # queremos que agrupe por páis
    .agg(mean("_5")) # que calcule la media de la columna para cada país
    .sort(F.col("avg(_5)"))) # queremos orden ascendente

desarrollo_DF_sol.show(10) # visualizamos la tabla creada y qué 10 países necesitams para ver su deuda acomulada

"""Creamos una tabla que contenga el nombre del pais y la deuda que queremos estudair qu eestá en la posión 5, además eliminamos la cabecera:"""

dt_deuda_DT_AMT_MLAT_CD= dt_deuda.map(lambda x: (x[0], x[5])).\
                filter(lambda x: x[0] != 'country_name')

"""Cambiamos el formato a tabla sql para que tenga el mismo formato que la tabla con los paises anteriores"""

dt_deuda_DT_AMT_MLAT_CD_DF = sqlContext.createDataFrame(dt_deuda_DT_AMT_MLAT_CD) # cambiamos a formato sql

dt_deuda_DT_AMT_MLAT_CD_DF.show(10) # visualizamos la forma de la tabla

"""Unimos las tablas para ver para cada pais el valor SP.DYN.CBRT.IN y el valor DT_AMT_MLAT_CD_DF. en este caso he elegido una join left ya que quiero para cada valor de la tabla 1 su valor DT_AMT_MLAT_CD_DF."""

data_join = desarrollo_DF_sol.join(dt_deuda_DT_AMT_MLAT_CD_DF,"_1","left")

data_join.take(1) # visualizamos que se ha credado correctamente

# Creamos una tabla con los paises que nos interesan a partir de la los 10 menores en SP.DYN.CBRT.IN 
data_join.createOrReplaceTempView("join_table")
    
    # Hacemos un WHERE para que nos vuelve solo aquellos paises que nos interesan:
join_df = sqlContext.sql("""
                SELECT _1, 'avg(_5)', _2
                FROM join_table 
                WHERE( _1 = 'Japan' OR
               _1 = 'San Marino' OR
                 _1 = 'Spain' OR
                 _1 = 'Hungary' OR
                 _1 = 'Singapore' OR
                _1 = 'Switzerland' OR
                 _1 = 'Ukraine' OR
                 _1 = 'Moldova' OR
                 _1 = 'Barbados' OR
                 _1 = 'Thailand')
                """)
join_df.show(10)

"""del resultado observamos que muchos de estos paises no están recoguidos en la tabla deuda, nos quedamos con los únicos dos países que sí estaán:"""

joindf_def= sqlContext.sql("""
                SELECT _1, 'avg(_5)', _2
                FROM table4 
                WHERE( _1 = 'Ukraine' OR
                 _1 = 'Moldova' OR
                 _1 = 'Thailand')
                """)

"""#### Solución:

Sumamos los valores de estospaíes para DT_AMT_MLAT_CD_DF
"""

joindf_def.select(sum("_2")).show()

"""##### 9. ¿Hay alguna relación entre los nacimientos y el indicador DT.AMT.DLXF.CD? ¿Cómo podrías demostrarlo?"""