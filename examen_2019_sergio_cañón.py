# -*- coding: utf-8 -*-
"""examen_2019_sergio_cañón.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14HMRbyp_3Ixk7NYS-Q_FXgO8Rrzdu95D

# 1. The World Bank's international debt data
<p>No es que los humanos solo tengamos deudas para administrar nuestras necesidades. Un país también puede endeudarse para administrar su economía. Por ejemplo, el gasto en infraestructura es un ingrediente costoso requerido para que los ciudadanos de un país lleven una vida cómoda. El Banco Mundial es la organización que proporciona deuda a los países.</p>

<!-- <p>En este notebook, vamos a analizar los datos de la deuda internacional recopilados por el Banco Mundial. El conjunto de datos contiene información sobre el monto de la deuda (en USD) que deben los países en desarrollo en varias categorías.</p>  -->

<p>Vamos a encontrar las respuestas a preguntas como:

<p>¿Cuál es el monto total de la deuda que deben los países enumerados en el conjunto de datos?
<p>¿Qué país posee la cantidad máxima de deuda y cómo se ve esa cantidad?
<p>¿Cuál es el monto promedio de la deuda de los países a través de diferentes indicadores de deuda?
    
Además tenemos otro dataset en el que encontramos información histórica de algunos índices de desarrollo, entre los que se encuentran algunos de deuda como son:

Series Name,Series Code
"Birth rate, crude (per 1,000 people)",SP.DYN.CBRT.IN

"Central government debt, total (current LCU)",GC.DOD.TOTL.CN

"Central government debt, total (% of GDP)",GC.DOD.TOTL.GD.ZS

# METADATOS
## DATA SET DESARROLLO
Birth rate, crude (per 1,000 people),SP.DYN.CBRT.IN
* Cause of death, by injury (% of total),SH.DTH.INJR.ZS
* Central government debt, total (current LCU),GC.DOD.TOTL.CN
* Central government debt, total (% of GDP),GC.DOD.TOTL.GD.ZS
* Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age),SH.ALC.PCAP.LI
* Total alcohol consumption per capita, female (liters of pure alcohol, projected estimates, female 15+ years of age),SH.ALC.PCAP.FE.LI
* Total alcohol consumption per capita, male (liters of pure alcohol, projected estimates, male 15+ years of age),SH.ALC.PCAP.MA.LI

## DATA SET DEUDA

indicator_name,indicator_code
* Disbursements on external debt, long-term (DIS, current US$),DT.DIS.DLXF.CD
* Interest payments on external debt, long-term (INT, current US$),DT.INT.DLXF.CD
* PPG, bilateral (AMT, current US$),DT.AMT.BLAT.CD
* PPG, bilateral (DIS, current US$),DT.DIS.BLAT.CD
* PPG, bilateral (INT, current US$),DT.INT.BLAT.CD
* PPG, multilateral (AMT, current US$),DT.AMT.MLAT.CD
* PPG, multilateral (DIS, current US$),DT.DIS.MLAT.CD
* PPG, multilateral (INT, current US$),DT.INT.MLAT.CD
* PPG, official creditors (AMT, current US$),DT.AMT.OFFT.CD
* PPG, official creditors (DIS, current US$),DT.DIS.OFFT.CD
* PPG, official creditors (INT, current US$),DT.INT.OFFT.CD
* Principal repayments on external debt, long-term (AMT, current US$),DT.AMT.DLXF.CD
* Interest payments on external debt, private nonguaranteed (PNG) (INT, current US$),DT.INT.DPNG.CD
* PPG, bonds (AMT, current US$),DT.AMT.PBND.CD
* PPG, bonds (INT, current US$),DT.INT.PBND.CD
* PPG, commercial banks (AMT, current US$),DT.AMT.PCBK.CD
* PPG, commercial banks (DIS, current US$),DT.DIS.PCBK.CD
* PPG, commercial banks (INT, current US$),DT.INT.PCBK.CD
* PPG, other private creditors (AMT, current US$),DT.AMT.PROP.CD
* PPG, other private creditors (DIS, current US$),DT.DIS.PROP.CD
* PPG, other private creditors (INT, current US$),DT.INT.PROP.CD
* PPG, private creditors (AMT, current US$),DT.AMT.PRVT.CD
* PPG, private creditors (DIS, current US$),DT.DIS.PRVT.CD
* PPG, private creditors (INT, current US$),DT.INT.PRVT.CD
* Principal repayments on external debt, private nonguaranteed (PNG) (AMT, current US$),DT.AMT.DPNG.CD

### 1. Inicializar y cargar el contexto spark

##### EN COLAB
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
!tar xf spark-2.4.7-bin-hadoop2.7.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.7-bin-hadoop2.7"

import findspark
findspark.init()
# en primer lugar inicio el contexto de Spark
from pyspark import SparkContext
sc = SparkContext.getOrCreate()

#debido a qeu trabajaremos con spark sql introducimos el sparksql
from pyspark.sql import *
spark = SparkSession.builder.master("local[*]").getOrCreate()

import re
import numpy as np
import pandas as pd

"""##### EN JUPYTER VIA DOCKER

"""

from pyspark import SparkContext 
from pyspark.sql import *
import seaborn as sns
import numpy as np
sc = SparkContext()
spark = SparkSession.builder.master("local[*]").getOrCreate()

conf = sc.getConf()
conf.getAll()

"""#### Parseado

"""

# importamos los csv y los pasamos a RDD

deuda_RDD = sc.textFile("indicadores_deuda.csv")
desarrollo_RDD = sc.textFile("indicadores_desarrollo.csv" )

"""#### Data set Desarrollo"""

# EDA de el RDD

desarrollo_RDD_top = desarrollo_RDD.take(1)[0] # seleccionamos la primera fila
desarrollo_RDD = desarrollo_RDD.filter(lambda x: x != desarrollo_RDD_top) # eliminamos la primera fila
print(desarrollo_RDD.count()) 
desarrollo_RDD.take(3)

def parseo_desarrollo_1(fila): # dos posibilidades de parseado
  """
  Función que indica cual de los dos regex sigue una determinada fila
  """
  regex = re.search('(\D+)\,(\D+)\,(\d{4}) \[\S{6}\]\,(\S+)\,(\S+)\,(\S+)',fila) # Paises sin espacios ni comas
  if regex is None:
    regex = re.search('(\D+\,\s+)[\D+]\,(\d{4}) \[\S{6}\]\,(\S+)\,(\S+)\,(\S+)',fila) # Con espacios, comillas o comas
  if regex is None:
    return (fila, 0)  # devuelve si coincide con uno u otro criterio anterior
  else:
    return (fila, 1)

def parseo_desarrollo_2(fila): 

  """ 
  Función que devuelve la fila parseada
  """
  
  regex = re.search("(\D+)\,(\D+)\,(\d{4}) \[\S{6}\]\,(\S+)\,(\S+)\,(\S+)", fila)
  if regex is None:
    regex  = re.search("(\D+\,\s+)[\D+]\,(\d{4}) \[\S{6}\]\,(\S+)\,(\S+)\,(\S+)", fila)
  return(regex.groups())

# division de las lineas en función de la rgex a aplicar
# primera expresion regex
#segunda expresión regex

parsed_rdd = desarrollo_RDD.map(lambda line: parseo_desarrollo_1(line)).filter(lambda line: line[1] == 1).map(lambda line : line[0]) 

 # aplica el parseo en función de lo anterior
desarrollo_parseado = parsed_rdd.map(lambda line: parseo_desarrollo_2(line))

print(desarrollo_RDD.count())
desarrollo_parseado.take(5)

"""
# Deuda"""

# seleccionamos la primera fila
deuda_RDD_top = deuda_RDD.take(1)[0] 
deuda_RDD = deuda_RDD.filter(lambda x: x != deuda_RDD_top) # eliminamos la primera fila

deuda_RDD.take(2)

def parseo_deuda_1(line):
  """
  Esta función susutituye caracteres qeu pueden dar problemas como las comillas o diferentes patrones.
  Las sustituyen por espacios
  """
  match = re.sub(r'"','',line)
  x = re.sub(r'\,\s{1}',' ',match)
  return x

#aplicamos sustitución

deuda_parseado = deuda_RDD.map(parseo_deuda_1).map(lambda x: x.split(",")) # parseado por comas

deuda_parseado.take(3)



"""### 2. Número de países distintos en cada dataset. Coinciden?"""

paises_desarrollo = desarrollo_parseado\
.map(lambda x: (x[0],1)) #selecionamos el nombre del pais y un uno por cada vez que esté el pais

paises_desarrollo.count()

paises_desarrollo = paises_desarrollo\
.reduceByKey(lambda a, b: a + b) #paises en el data set de desarrollo


paises_desarrollo.collect()

paises_deuda = deuda_parseado\
.map(lambda x: (x[0],1))\
.reduceByKey(lambda a, b: a + b) #paises en el data set de deuda y las veces repetido

paises_deuda.collect()

# join para saber los paises comunes. En la deuda solo se repiten una vez

paises_coinciden = paises_desarrollo.join(paises_deuda)
paises_coinciden.collect()

"""
### 3. Total de deuda contraida por cada pais: total amount of debt (in USD) DT.AMT.MLAT.CD"""

# filtramos nulos
# elegimos pais y columna correspondiente a al variable

total_amount_of_debt = deuda_parseado\
.filter(lambda x: x[2] is not '')\
.map(lambda x: (x[0],float(x[2])))

total_amount_of_debt.collect()



"""## 4. Media de los indicadores de deuda (tabla uno): DT.AMT.BLAT.CD, DT.DIS.BLAT.CD, DT.INT.BLAT.CD

### DT.AMT.BLAT.CD
"""

#Denominador de la media

observaciones_DTAMTBLATCD = deuda_parseado\
.filter(lambda x: x[2] is not '') #filtro nulos

N = observaciones_DTAMTBLATCD.count() #N

#Numerador de la media

# division de x entre N
# sumo cada x/N

media_DTAMTBLATCD = observaciones_DTAMTBLATCD\
.map(lambda x: float(x[2])/N)\
.reduce(lambda x, y: x + y) 

# RESULTADO
print("Media del indicador de deuda DT.AMT.BLAT.CD:" , media_DTAMTBLATCD)

""" ### DT.DIS.BLAT.CD"""

#Denominador de la media

observaciones_DTDISBLATCD = deuda_parseado\
.filter(lambda x: x[11] is not '')
N = observaciones_DTDISBLATCD.count()

#Numerador de la media

# division de x entre N
# sumo cada x/N

media_DTDISBLATCD = observaciones_DTDISBLATCD\
.map(lambda x: float(x[11])/N)\
.reduce(lambda x, y: x + y)

# RESULTADO
print("Media del indicador de deuda  DT.DIS.BLAT.CD:" , media_DTDISBLATCD)

""" ### DT.INT.BLAT.CD"""

#Denominador de la media

observaciones_DTINTBLATCD = deuda_parseado.filter(lambda x: x[18] is not '')
N = observaciones_DTINTBLATCD.count()

#Numerador de la media

# division de x entre N
# sumo cada x/N

media_DTINTBLATCD = observaciones_DTINTBLATCD.map(lambda x: float(x[18])/N).reduce(lambda x, y: x + y)

# RESULTADO

print("Media del indicador de deuda  DT.INT.BLAT.CD:" , media_DTINTBLATCD)

"""## 5. Los 20 paises con DT.AMT.DLXF.CD más alto"""

# filtro nulos
#seleciono columna y nombre pais
#ordeno por valor de la variable númerica como key
# cogemos las 20 primeras


top_20_DT_AMT_DLXF_CD = deuda_parseado\
.filter(lambda x: x[3] is not '')\
.map(lambda x: (float(x[3]),x[0]))\
.sortByKey(False)\
.take(20)

# RESULTADO

top_20_DT_AMT_DLXF_CD



"""## 6. Pais con los datos informados todos los años."""

numero_años = desarrollo_parseado\
.map(lambda x: x[2])\
.distinct() # devuelve cada valor diferente

print("Hay", numero_años.count(), " diferentes años y son ", numero_años.collect())

datos_años_pais = desarrollo_parseado.map(lambda x: (x[0],1))\ # paises y un 1 para contar
.reduceByKey(lambda x,y: x+y)\  # suma de las veces que aparecen
.filter(lambda x: x[1]==4)  # filtro para 4 años (máximo)

# RESULTADO

datos_años_pais.collect() #pais con todos los años



"""## 7. Media anual de los distintos indicadores de desarrollo

#### "Central government debt, total (current LCU)",GC.DOD.TOTL.CN
"""

# extragio pais y columna a estudiar

media_indicadores_governmentdebt_0_1 = desarrollo_parseado\
.map(lambda x: (x[2], float(x[3])))\
.reduceByKey(lambda a, b: a + b)

media_indicadores_governmentdebt_1_1 = desarrollo_parseado\
.map(lambda x: (x[2],1))\
.reduceByKey(lambda x,y: x + y)



media_indicadores_governmentdebt_2 = media_indicadores_governmentdebt_0_1\
.join(media_indicadores_governmentdebt_1_1)

media_indicadores_governmentdebt = media_indicadores_governmentdebt_2\
.map(lambda x: (x[0], x[1][0]/x[1][1]))\
.sortByKey()\
.collect()

# RESULTADO

media_indicadores_governmentdebt



"""#### Birth rate, crude (per 1,000 people),SP.DYN.CBRT.IN"""

# extragio pais y columna a estudiar

media_indicadores_birthrate_0_1 = desarrollo_parseado\
.map(lambda x: (x[2], float(x[5])))\       
.reduceByKey(lambda a, b: a + b)

#pais y numero de veces que aparece el pais en el data set

media_indicadores_birthrate_1_1 = desarrollo_parseado\
.map(lambda x: (x[2],1))\
.reduceByKey(lambda x,y: x + y)

# join para juntar ambos RDD
media_indicadores_birthrate_2 = media_indicadores_birthrate_0_1\
.join(media_indicadores_birthrate_1_1)

media_indicadores_birthrate = media_indicadores_birthrate_2\
.map(lambda x: (x[0], x[1][0]/x[1][1]))\
.sortByKey()\
.collect()

media_indicadores_birthrate



"""#### Central government debt, total (% of GDP),GC.DOD.TOTL.GD.ZS"""

# extragio pais y columna a estudiar

media_indicadores_governmentdebt_percent_0_1 = desarrollo_parseado\
.map(lambda x: (x[2], float(x[4])))\
.reduceByKey(lambda a, b: a + b)

#pais y numero de veces que aparece el pais en el data set

media_indicadores_governmentdebt_percent_1_1 = desarrollo_parseado\
.map(lambda x: (x[2],1))\
.reduceByKey(lambda x,y: x + y)

# join para juntar ambos RDD

media_indicadores_governmentdebt_percent_2 = media_indicadores_governmentdebt_percent_0_1.join(media_indicadores_governmentdebt_percent_1_1)

media_indicadores_governmentdebt_percent = media_indicadores_governmentdebt_percent_2\
.map(lambda x: (x[0], x[1][0]/x[1][1]))\
.sortByKey().collect()


# RESULTADO

media_indicadores_governmentdebt_percent



"""### 8. Podrías decirme el total de deuda acumulada DT.AMT.MLAT.CD por los 10 países con un valor en media menor de SP.DYN.CBRT.IN"""

desarrollo_parseado_0 = desarrollo_parseado.map(lambda x: (x[0], float(x[5]))).reduceByKey(lambda a, b: a + b)  # sumamos indicador por cada pais
desarrollo_parseado_0.take(5)

desarrollo_parseado_1 = desarrollo_parseado.map(lambda x: (x[0],1)).reduceByKey(lambda a, b: a + b) #pais y numero de veces que aparece el pais en el data set
desarrollo_parseado_1.take(5)

desarrollo_parseado_2 = desarrollo_parseado_0.join(desarrollo_parseado_1) #join key=pasi, value=(Sumatorio, N)
desarrollo_parseado_2.take(5)

desarrollo_parseado_3 = desarrollo_parseado_2.map(lambda x:  (x[1][0]/x[1][1], x[0])).sortByKey() # media
desarrollo_parseado_3.take(5)

desarrollo_parseado_4 = desarrollo_parseado_3.map(lambda x: (x[1], x[0])) # cambio el key/value para poder hacer un join por key
desarrollo_parseado_4.take(5)



desarrollo_parseado_5 = deuda_parseado.filter(lambda x: x[2] is not '').map(lambda x: (x[0],float(x[2])))
desarrollo_parseado_5.take(5)

deuda_acumulada_menor_indice_natalida_0 = desarrollo_parseado_4.join(desarrollo_parseado_5)
deuda_acumulada_menor_indice_natalida_0.take(5)

deuda_acumulada_menor_indice_natalidad = deuda_acumulada_menor_indice_natalida_0.map(lambda x: (x[1][0], (x[0], x[1][1]))).sortByKey()
deuda_acumulada_menor_indice_natalidad.take(5)

# RESULTADO

deuda_acumulada_top_10_menor_indice_natalidad = deuda_acumulada_menor_indice_natalidad.map(lambda x: (x[1][0],x[1][1])).take(10)
deuda_acumulada_top_10_menor_indice_natalidad





"""### 9. ¿Hay alguna relación entre los nacimientos y el indicador DT.AMT.DLXF.CD? ¿Cómo podrías demostrarlo?"""

#aprovecho el RDD anterior para hacer el ejercicio

desarrollo_parseado_4.collect()
nacimientos_2 = desarrollo_parseado_4
.map(lambda x: (x[1],x[0]))
nacimientos_2.take(1)

DT_AMT_DLXF_CD = deuda_parseado.filter(lambda x: x[3] is not '').map(lambda x: (x[0], float(x[3])))

nacimientos_indicador = DT_AMT_DLXF_CD.join(nacimientos_2).map(lambda x: (x[0] ,x[1][0] ,x[1][1])).collect() # juntamos pais e indicadores para corresponder nacimientos/indicador y luego escogemos solo los indicadores

nacimientos_indicador

nacimientos_indicador_df = spark.createDataFrame(nacimientos_indicador, schema=['País','DT.AMT.DLXF.CD', 'Nacimientos']).toPandas()
nacimientos_indicador_df

nacimientos_indicador_df['DT.AMT.DLXF.CD'] = np.log(nacimientos_indicador_df['DT.AMT.DLXF.CD']) #rpobamos en logaritmos
nacimientos_indicador_df



plt.figure(figsize=(10,5))
plt.xlabel("DT.AMT.DLXF.CD")
plt.ylabel("Nacimientos")
plt.scatter("DT.AMT.DLXF.CD", "Nacimientos", data=nacimientos_indicador_df);

nacimientos_indicador_df.corr()

"""No podemos establecer ninguna relación

"""

#docker
sc.stop()

#

"""# FUENTES 
* Apuntes
* Libro :  "Learning PySpark"
* Datacamp: Big Data fundamentals with pyspark
* https://regexr.com/
"""